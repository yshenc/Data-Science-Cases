{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter\n",
    "\n",
    "Due Date: September 21, **BEFORE the beginning of class at 6:00pm**\n",
    "\n",
    "## **NOTE: There are *always* last minute issues submitting the case studies.  DO NOT WAIT UNTIL THE LAST MINUTE!**\n",
    "\n",
    "* ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/9f/Twitter_bird_logo_2012.svg/220px-Twitter_bird_logo_2012.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
    "\n",
    "    Yao Chun Hsieh\n",
    "    Nathan Hsu\n",
    "    Yuchen Shen\n",
    "    Yang Tao\n",
    "    Ying Fang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://www.learndatasci.com/wp-content/uploads/2015/08/Mining-the-Social-Web-2nd-Edition.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sampling Twitter Data with Streaming API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    # Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = 'ScmFh6jc3YxqwcNxCQrKon3nS'\n",
    "    CONSUMER_SECRET = 'GK01LyBIQFq4pM3UdYXashxTKfWRNCtEnpjDdlJLLVoM1PrCsc'\n",
    "    OAUTH_TOKEN = '906960184504979457-vvdrt7JqA2OBtXCbcw4theY6wbaOirJ'\n",
    "    OAUTH_TOKEN_SECRET = 'kgQQ0G46MoAntkc0PGEplf6a1MkyRsw83gbDHs1cTFlyU'\n",
    "\n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of statuses 100\n",
      "Length of statuses 200\n",
      "Length of statuses 300\n",
      "Length of statuses 400\n",
      "Length of statuses 500\n",
      "Length of statuses 508\n",
      "Data Saved: SteveJobs Theater-170919_223450(508).txt\n"
     ]
    }
   ],
   "source": [
    "# Import unquote to prevent url encoding errors in next_results\n",
    "from urllib.parse import quote, unquote\n",
    "from datetime import datetime\n",
    "\n",
    "# Query Setting\n",
    "keyWord = 'SteveJobs Theater'\n",
    "count = 100\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "search_results = twitter_api.search.tweets(q=keyWord, count=count)\n",
    "statuses = search_results['statuses']\n",
    "\n",
    "# Iterate through 10 more batches of results by following the cursor\n",
    "for _ in range(5):\n",
    "    print(\"Length of statuses\", len(statuses))\n",
    "    try:\n",
    "        next_results = search_results['search_metadata']['next_results']\n",
    "    except KeyError: # No more results when next_results doesn't exist\n",
    "        break\n",
    "        \n",
    "    # Create a dictionary from next_results, which has the following form:\n",
    "    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "    kwargs = dict([ kv.split('=') for kv in unquote(next_results[1:]).split(\"&\") ])\n",
    "    \n",
    "    search_results = twitter_api.search.tweets(**kwargs)\n",
    "    statuses += search_results['statuses']\n",
    "\n",
    "import json\n",
    "print(\"Length of statuses\", len(statuses))\n",
    "data = json.dumps(statuses, indent=4)\n",
    "    \n",
    "curTime = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "fileDirectory = \"%s-%s(%s).txt\" % (keyWord, curTime, str(len(statuses)))\n",
    "    \n",
    "file = open(fileDirectory,'w')\n",
    "file.write(data)\n",
    "file.close()\n",
    "print(\"Data Saved: \" + fileDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: SteveJobs Theater\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"SteveJobs Theater-170919_223450(508).txt\") as tweetfile:\n",
    "    statuses = json.load(tweetfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "status_texts = [status['text']\n",
    "                for status in statuses]\n",
    "\n",
    "# Compute a collection of all words from all tweets\n",
    "words = [w\n",
    "         for t in status_texts\n",
    "             for w in t.split()]\n",
    "\n",
    "screen_names = [user_mention['screen_name']\n",
    "                for status in statuses\n",
    "                    for user_mention in status['entities']['user_mentions']]\n",
    "\n",
    "hashtags = [hashtag['text']\n",
    "            for status in statuses\n",
    "                for hashtag in status['entities']['hashtags']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------+\n",
      "| Word                    | Count |\n",
      "+-------------------------+-------+\n",
      "| RT                      |   326 |\n",
      "| #AppleEvent             |   247 |\n",
      "| SteveJobs               |   208 |\n",
      "| #SteveJobs              |   206 |\n",
      "| the                     |   186 |\n",
      "| Theater                 |   183 |\n",
      "| Theater„ÅÆ‰∏≠„Åß„ÅôÔºÅ       |   162 |\n",
      "| https://t.co/FH0DmygoBu |   162 |\n",
      "| @gizmodojapan:          |   161 |\n",
      "| at                      |   125 |\n",
      "| #Apple's                |   101 |\n",
      "| for                     |    97 |\n",
      "| #iPhoneX                |    90 |\n",
      "| #iPhone8                |    71 |\n",
      "| &amp;                   |    68 |\n",
      "| @appleinsider:          |    67 |\n",
      "| live                    |    64 |\n",
      "| unveiling               |    62 |\n",
      "| Steve                   |    60 |\n",
      "| event                   |    60 |\n",
      "| Join                    |    60 |\n",
      "| Jobs                    |    58 |\n",
      "| @AppleInsider           |    56 |\n",
      "| https://t.co/0mo6UQHrbp |    56 |\n",
      "| #stevejobs              |    55 |\n",
      "| http‚Ä¶                   |    55 |\n",
      "| new                     |    38 |\n",
      "| to                      |    37 |\n",
      "| #apple                  |    34 |\n",
      "| from                    |    34 |\n",
      "+-------------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "'''For future, we should remove meaningless word like 'a', 'the', 'an', 'is'... etc.\n",
    "   and, we should see a word in both Upper/Lower case as the same word'''\n",
    "\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "pt = PrettyTable(field_names=['Word', 'Count']) \n",
    "c = Counter(words)\n",
    "[pt.add_row(kv) for kv in c.most_common()[:30]]\n",
    "pt.align['Word'], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------------------------------------------------+\n",
      "| Count | Screen Name  | Text                                               |\n",
      "+-------+--------------+----------------------------------------------------+\n",
      "| 208   | gizmodojapan | RT @gizmodojapan: SteveJobs Theater„ÅÆ‰∏≠„Åß„ÅôÔºÅ      |\n",
      "|       |              | #AppleEvent https://t.co/FH0DmygoBu                |\n",
      "| 62    | appleinsider | RT @appleinsider: Join @AppleInsider live at the   |\n",
      "|       |              | #SteveJobs Theater for #Apple's #iPhoneX &amp;     |\n",
      "|       |              | #iPhone8 unveiling https://t.co/0mo6UQHrbp http‚Ä¶   |\n",
      "| 51    | appleinsider | RT @appleinsider: Latest #ApplePark drone video    |\n",
      "|       |              | shows completed #SteveJobs Theater ahead of Sept.  |\n",
      "|       |              | 12 event https://t.co/2bnK1ad8if https://‚Ä¶         |\n",
      "| 21    | yuuuuuiiiii  | RT @yuuuuuiiiii: SteveJobs                         |\n",
      "|       |              | Theater„ÅØSF„ÅÆ„ÉØ„É≥„Ç∑„Éº„É≥„ÅÆ„Çà„ÅÜ„Å†„ÄÇÈü≥Ê•Ω„ÇÇ„ÅÑ„ÅÑ„ÄÇ„Åß„ÇÇ„ÄÅ„Åì„Åì„Å´„ÅØ‰Ωï„Å´„ÇÇ„Å™„ÅÑ„ÅÆ„ÄÇ |\n",
      "|       |              | #AppleEvent https://t.co/inqftw2qcQ                |\n",
      "| 20    | yuuuuuiiiii  | RT @yuuuuuiiiii:                                   |\n",
      "|       |              | ‰∫∫„ÅØÊ≠ª„Çì„Å†„Çâ„Åì„Åì„Å´Ë°å„Åè„ÅÆ„Åã„Å™Ôºü„Å£„Å¶„Åè„Çâ„ÅÑ„Åç„Çå„ÅÑ„ÄÇÁõ¥ÂæÑ50„É°„Éº„Éà„É´„ÅÆSteveJobs Theater |\n",
      "|       |              | „ÄÇ360Â∫¶„Ç¨„É©„Çπ„Å†„Åã„ÇâÂ§ïÁÑº„Åë„Å´Êüì„Åæ„Å£„Å¶‰∏ÄÈù¢„Éî„É≥„ÇØËâ≤„Å´„Å™„Çã„Çì„Å†„Å£„Å¶„ÄÇ  #AppleEvent |\n",
      "|       |              | https://t.co/sqWMftEptG                            |\n",
      "| 13    | appleinsider | RT @appleinsider: .@CityofCupertino approved#      |\n",
      "|       |              | SteveJobs Theater occupancy after #iPhoneX event   |\n",
      "|       |              | invites sent https://t.co/LQNZbDx5pz https:/‚Ä¶      |\n",
      "| 7     | cpassariello | RT @cpassariello: .@Apple campus opens to the      |\n",
      "|       |              | public for the first time for #AppleEvent at       |\n",
      "|       |              | #SteveJobs Theater. https://t.co/BgmyWulffq        |\n",
      "| 4     | ipadnews     | RT @ipadnews: New Apple Park Drone Video of Steve  |\n",
      "|       |              | Jobs Theater Ahead of Sept 12 iPhone Launch        |\n",
      "|       |              | #applepark #stevejobs #applecampus https://t.‚Ä¶     |\n",
      "| 4     | IntuzHQ      | RT @IntuzHQ: Apple #iPhoneX event: the 5 most      |\n",
      "|       |              | important announcements from #SteveJobs Theater.   |\n",
      "|       |              | #AppleEvent                                        |\n",
      "|       |              | https://t.co/n42zqXCjti https://‚Ä¶                  |\n",
      "| 3     | rajmathai    | RT @rajmathai: Ready for takeoff: New #SteveJobs   |\n",
      "|       |              | theater @Apple spaceship HQ. #iPhone8              |\n",
      "|       |              | https://t.co/h0h0zKnxpF                            |\n",
      "+-------+--------------+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "retweets = []\n",
    "for status in statuses:\n",
    "    L = []\n",
    "    for i in retweets:\n",
    "        L.append(i[2])\n",
    "    if status['text'] in L:\n",
    "        continue\n",
    "    if 'retweeted_status' in status:\n",
    "        retweets.append(\n",
    "             (status['retweet_count'], \n",
    "             status['retweeted_status']['user']['screen_name'],\n",
    "             status['text']))      \n",
    "           \n",
    "\n",
    "# Slice off the first 5 from the sorted results and display each item in the tuple\n",
    "\n",
    "pt = PrettyTable(field_names=['Count', 'Screen Name', 'Text'])\n",
    "[pt.add_row(row) for row in sorted(retweets, reverse=True)[:10]]\n",
    "pt.max_width['Text'] = 50\n",
    "pt.align= 'l'\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "| Hashtag    | Count |\n",
      "+------------+-------+\n",
      "| AppleEvent |   257 |\n",
      "| SteveJobs  |   212 |\n",
      "| Apple      |   136 |\n",
      "| iPhoneX    |    92 |\n",
      "| iPhone8    |    72 |\n",
      "| stevejobs  |    56 |\n",
      "| apple      |    34 |\n",
      "| iPhone     |    26 |\n",
      "| iphone8    |    23 |\n",
      "| Theater    |    19 |\n",
      "+------------+-------+\n",
      "+-----------------+-------+\n",
      "| Screen Name     | Count |\n",
      "+-----------------+-------+\n",
      "| gizmodojapan    |   161 |\n",
      "| appleinsider    |   123 |\n",
      "| yuuuuuiiiii     |    36 |\n",
      "| Apple           |    30 |\n",
      "| CityofCupertino |    12 |\n",
      "| cpassariello    |     7 |\n",
      "| tim_cook        |     6 |\n",
      "| arstechnica     |     4 |\n",
      "| IntuzHQ         |     4 |\n",
      "| DHQLounge       |     4 |\n",
      "+-----------------+-------+\n"
     ]
    }
   ],
   "source": [
    "'''We should remove meaningless word like 'a', 'the', 'an', 'is'... etc.'''\n",
    "'''We should see a word in both Upper/Lower case as the same word'''\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "for label, data in (('Hashtag', hashtags),\n",
    "                    ('Screen Name', screen_names)\n",
    "                   ):\n",
    "    pt = PrettyTable(field_names=[label, 'Count']) \n",
    "    c = Counter(data)\n",
    "    [pt.add_row(kv) for kv in c.most_common()[:10]]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ------------------------\n",
    "\n",
    "# Problem 3: Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetScreenName = \"pricechopper\"\n",
    "\n",
    "#Chapter 9 Solution for All friends and follwers\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from urllib.request import URLError\n",
    "from http.client import BadStatusLine\n",
    "import json\n",
    "import twitter\n",
    "\n",
    "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw): \n",
    "    \n",
    "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
    "    # value for wait_period if the problem is a 500 level error. Block until the\n",
    "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
    "    # for 401 and 404 errors, which requires special handling by the caller.\n",
    "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "    \n",
    "        if wait_period > 3600: # Seconds\n",
    "            raise e\n",
    "    \n",
    "        # See https://dev.twitter.com/docs/error-codes-responses for common codes  \n",
    "        if e.e.code == 401:\n",
    "            return None\n",
    "        elif e.e.code == 404:\n",
    "            return None\n",
    "        elif e.e.code == 429:\n",
    "            if sleep_when_rate_limited:\n",
    "                time.sleep(60*15 + 5)\n",
    "                return 2\n",
    "            else:\n",
    "                raise e # Caller must handle the rate limiting issue\n",
    "        elif e.e.code in (500, 502, 503, 504):\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            return wait_period\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # End of nested helper function\n",
    "    \n",
    "    wait_period = 2 \n",
    "    error_count = 0 \n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return twitter_api_func(*args, **kw)\n",
    "        except twitter.api.TwitterHTTPError as e:\n",
    "            error_count = 0 \n",
    "            wait_period = handle_twitter_http_error(e, wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "        except URLError as e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            if error_count > max_errors:\n",
    "                raise\n",
    "        except BadStatusLine as e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            if error_count > max_errors:\n",
    "                raise\n",
    "\n",
    "# Sample usage\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/users/lookup for \n",
    "# twitter_api.users.lookup\n",
    "#twitter_api = oauth_login()\n",
    "#response = make_twitter_request(twitter_api.users.lookup, screen_name=\"tim_cook\")\n",
    "\n",
    "\n",
    "#Chapter 9 Solution for All friends and follwers\n",
    "#retrieve every result and write into .txt immediately\n",
    "from functools import partial\n",
    "import tabulate\n",
    "def get_friends_followers_info(twitter_api, screen_name=None, user_id=None):\n",
    "    \n",
    "    # Must have either screen_name or user_id (logical xor)\n",
    "    assert (screen_name != None) != (user_id != None), \\\n",
    "    \"Must have screen_name or user_id, but not both\"\n",
    "    \n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/friends/ids and\n",
    "    # https://dev.twitter.com/docs/api/1.1/get/followers/ids for details\n",
    "    # on API parameters\n",
    "    \n",
    "    get_friends_list = partial(make_twitter_request, twitter_api.friends.list, count=200)\n",
    "    get_followers_list = partial(make_twitter_request, twitter_api.followers.list, count=200)\n",
    "\n",
    "    friends_info, followers_info = [], []\n",
    "    \n",
    "    for twitter_api_func, info, label in [\n",
    "                    [get_friends_list, friends_info, \"friends\"], \n",
    "                    [get_followers_list, followers_info, \"followers\"]\n",
    "                ]:\n",
    "        \n",
    "        cursor = -1\n",
    "        while cursor !=0:\n",
    "        \n",
    "            # Use make_twitter_request via the partially bound callable...\n",
    "            if screen_name: \n",
    "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
    "            else: # user_id\n",
    "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
    "\n",
    "            if response is not None:\n",
    "                for user in response['users']:\n",
    "                    info.append((user['id'], user['screen_name']))\n",
    "                    file = open(label+'.txt','a')\n",
    "                    file.write(str(info[-1])+'\\n')\n",
    "                    file.close()\n",
    "                cursor = response['next_cursor']\n",
    "                \n",
    "        \n",
    "            # XXX: You may want to store data during each iteration to provide an \n",
    "            # an additional layer of protection from exceptional circumstances     \n",
    "            if response is None:\n",
    "                break\n",
    "        file = open(label+'.txt','a')\n",
    "        file.write(str(len(info))+'\\n')\n",
    "        file.close()\n",
    "    # Do something useful with the IDs, like store them to disk...\n",
    "    return friends_info, followers_info\n",
    "twitter_api = oauth_login()\n",
    "friends_info, followers_info = get_friends_followers_info(twitter_api, screen_name = targetScreenName )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print 20 of friends and followers\n",
    "f= open('followers.txt', 'r')\n",
    "followers_info=[]\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    followers_info.append((values[0][1:-1],values[1][1:-2]))\n",
    "f.close()\n",
    "f= open('friends.txt', 'r')\n",
    "friends_info=[]\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    friends_info.append((values[0][1:-1],values[1][1:-2]))\n",
    "f.close()\n",
    "count = 20\n",
    "print(\"List %d Friend/Followers of %s: \" % (count, targetScreenName))\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "for label, data in (('Friends', friends_info),\n",
    "                    ('Followers', followers_info)\n",
    "                   ):\n",
    "    pt = PrettyTable(field_names=['ID', label]) \n",
    "    [pt.add_row(row) for row in data[:count]]\n",
    "    pt.align['ID'], pt.align[label] = 'l', 'l' # Set column alignment\n",
    "    print(pt)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'friends_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-72b6ea3ed265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#   Please feel free to add more cells below this cell if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmutuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfriends_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollowers_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprettytable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrettyTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'friends_info' is not defined"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "    \n",
    "#print 20 mutual\n",
    "f= open('followers.txt', 'r')\n",
    "followers_info=[]\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    followers_info.append((values[0][1:-1],values[1][1:-2]))\n",
    "f.close()\n",
    "f= open('friends.txt', 'r')\n",
    "friends_info=[]\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    friends_info.append((values[0][1:-1],values[1][1:-2]))\n",
    "f.close()\n",
    "mutuals = list(set(friends_info).intersection(followers_info))\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "pt = PrettyTable(field_names=['ID', 'Mutual Friends']) \n",
    "[pt.add_row(row) for row in mutuals[:count]]\n",
    "pt.align['ID'], pt.align['Mutual Friends'] = 'l', 'l' # Set column alignment\n",
    "print(pt)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "# Problem 4: Business question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "from prettytable import PrettyTable\n",
    "import sys\n",
    "import time\n",
    "from urllib.request import URLError\n",
    "from http.client import BadStatusLine\n",
    "import json\n",
    "import twitter\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    # Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = 'ScmFh6jc3YxqwcNxCQrKon3nS'\n",
    "    CONSUMER_SECRET = 'GK01LyBIQFq4pM3UdYXashxTKfWRNCtEnpjDdlJLLVoM1PrCsc'\n",
    "    OAUTH_TOKEN = '906960184504979457-vvdrt7JqA2OBtXCbcw4theY6wbaOirJ'\n",
    "    OAUTH_TOKEN_SECRET = 'kgQQ0G46MoAntkc0PGEplf6a1MkyRsw83gbDHs1cTFlyU'\n",
    "\n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "allFiles = []\n",
    "def getFileName(path):\n",
    "    ''' Ëé∑ÂèñÊåáÂÆöÁõÆÂΩï‰∏ãÁöÑÊâÄÊúâÊåáÂÆöÂêéÁºÄÁöÑÊñá‰ª∂Âêç '''\n",
    "\n",
    "    f_list = os.listdir(path)\n",
    "    # print f_list\n",
    "    for i in f_list:\n",
    "        # os.path.splitext():ÂàÜÁ¶ªÊñá‰ª∂Âêç‰∏éÊâ©Â±ïÂêç\n",
    "        if os.path.splitext(i)[1] == '.txt':\n",
    "            allFiles.append(i)\n",
    "getFileName('/Users/shenyuchen/Desktop/NoCountAttheEnd/iPhone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Saved: output170913_154922iphoneX.txt\n",
      "[(10091654, 'JohnCena', 267219), (396409, 'TopAchat', 52357), (697, 'nakurubox', 23732), (6367708, 'IGN', 18472), (53, 'Cerberus_Ignite', 16795), (12601, '_Do_t', 14361), (335885, 'ceemeagain', 9160), (956948, 'priwpriww', 7733), (47, 'biggie_teethara', 7633), (192, 'cowboy751', 7236), (997, 'its_kachi', 7202), (2931, 'ElijahMiano', 7002), (12600, '_Do_t', 6910), (811405, 'KTHopkins', 6381), (94780, 'SuperSaf', 6149)]\n",
      "+--------+-----------------+-----------------+----------------------------------------------------+\n",
      "| Count  | followers_count | Screen Name     | Text                                               |\n",
      "+--------+-----------------+-----------------+----------------------------------------------------+\n",
      "| 267219 | 10091654        | JohnCena        | RT @JohnCena: Sooo #iPhoneX about #FaceID          |\n",
      "|        |                 |                 | ...ummmmm .... what do I do?                       |\n",
      "| 52357  | 396409          | TopAchat        | RT @TopAchat: üéÅ #Concours üéÅ                        |\n",
      "|        |                 |                 |                                                    |\n",
      "|        |                 |                 | 2 #iPhoneX √† gagner ! üò±                            |\n",
      "|        |                 |                 |                                                    |\n",
      "|        |                 |                 | RT + Follow @TopAchat                              |\n",
      "|        |                 |                 | Mentionne un ami en r√©ponse (un iPhone X chacun)   |\n",
      "|        |                 |                 | https://t.co/F‚Ä¶                                    |\n",
      "| 23732  | 697             | nakurubox       | RT @nakurubox: „ÄåiPhoneX„ÅÆ‰æ°Ê†º„Åß„Åô„Äç               |\n",
      "|        |                 |                 | „ÄéÈ´ò„Åè„Å™„ÅÑ„Åã„Äè                                     |\n",
      "|        |                 |                 | „Äå„Çè„Åã„Çä„Å´„Åè„ÅÑ„ÅÆ„Åß„Ç¨„ÉÅ„É£ÂõûÊï∞„Å´„Åó„Åæ„Åó„Åü„Äç           |\n",
      "|        |                 |                 | „ÄéÂÆâ„ÅÑÔºÅ„Äè https://t.co/2GStha4MGo                 |\n",
      "| 18472  | 6367708         | IGN             | RT @IGN: This is the #iPhoneX. Do you want one?    |\n",
      "|        |                 |                 | #AppleEvent https://t.co/1RklfZYlFQ                |\n",
      "| 16795  | 53              | Cerberus_Ignite | RT @Cerberus_Ignite: iPhoneX„ÅÆ„ÉØ„Ç§„É§„É¨„ÇπÂÖÖÈõª„Åå„Éà„É¨„É≥„Éâ„Å´„Å™„Å£„Å¶„Çã„Åë„Å©„ÄÅ |\n",
      "|        |                 |                 |                                                    |\n",
      "|        |                 |                 | ÈÅéÂéª„Å´„Åù„ÅÆÊ©üËÉΩÊê≠Ëºâ„Åó„ÅüAndroid„Çí‰Ωø„Å£„Å¶„Åü‰ø∫„ÅåÂø†Âëä„Åô„Çã„Åû |\n",
      "|        |                 |                 |                                                    |\n",
      "|        |                 |                 | ÂÖÖÈõª„Åó„Å™„Åå„Çâ„Çπ„Éû„Éõ‰Ωø„Åà„Å™„ÅÑ„Åã„Çâ„ÅÑ„Çâ„Å™„ÅÑ             |\n",
      "| 14361  | 12601           | _Do_t           | RT @_Do_t: iPhoneX„ÅåÁô∫Ë°®„Åï„Çå„Åü„Åë„Å©„Å©„Çì„Å™„ÅÆ„Åã„Çà„ÅèÂàÜ„Åã„Çâ„ÇìÔºÅ„Å®„ÅÑ„ÅÜËñÑÊ±ö„ÅÑ„Ç™„É´„Éï„Çß„Éé„ÇØ |\n",
      "|        |                 |                 | „Åü„Å°„ÅÆ„Åü„ÇÅ„Å´„ÄÅÂêåÊôÇÊúü„Å´Áô∫Ë°®„Åï„Çå„Åü„Ç´„Ç§„Ç∂„Éï„Ç©„É≥„Å®„ÅÆÂàÜ„Åã„Çä„ÇÑ„Åô„ÅÑÊØîËºÉË°®„Åä„ÅÑ„Å®„Åç„Åæ„Åô„Å≠„ÄÇ |\n",
      "|        |                 |                 | https://t.co/zJN4p0vA04                            |\n",
      "| 9160   | 335885          | ceemeagain      | RT @ceemeagain: ‡∏ä‡∏≠‡∏ö‡∏ö‡∏ö‡∏ö ‡∏°‡∏≤‡∏Å‡∏Å‡∏Å‡∏Å‡∏Å ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏≠‡πÇ‡∏ü‡∏ô8       |\n",
      "|        |                 |                 | ‡πÄ‡∏≠‡∏≤‡∏°‡∏≤‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏±‡∏ö‡∏≠‡∏¥‡πÇ‡∏°‡∏à‡∏¥‡∏Å‡∏≥‡∏Å‡∏±‡∏ö                             |\n",
      "|        |                 |                 | ‡∏≠‡∏µ‡πÇ‡∏°‡∏à‡∏¥‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ #AR#iphoneX         |\n",
      "|        |                 |                 | https://t.co/krsfw7J3K7                            |\n",
      "| 7733   | 956948          | priwpriww       | RT @priwpriww: ‡∏ï‡∏•‡∏Å‡∏ó‡∏ß‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å‡πÑ‡∏≠‡πÇ‡∏ü‡∏ô8‡∏ï‡∏Å‡∏£‡∏∏‡πà‡∏ô‡∏≠‡∏∞            |\n",
      "|        |                 |                 | 55555555 ‡∏ß‡∏á‡∏ß‡∏≤‡∏£ ‡∏û‡∏∂‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤2‡∏ß‡∏¥ ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏≠‡πÇ‡∏ü‡∏ôX ‡∏°‡∏≤           |\n",
      "|        |                 |                 | ‡∏≠‡∏∞‡∏•‡∏∑‡∏°‡∏Å‡∏π‡πÄ‡∏•‡∏¢ ‡πÄ‡∏≠‡∏≤‡∏Å‡∏π‡∏°‡∏≤‡∏ó‡∏≥‡πÑ‡∏°55555 #iPhone8TH #iPhoneX      |\n",
      "| 7633   | 47              | biggie_teethara | RT @biggie_teethara:                               |\n",
      "|        |                 |                 | ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡πÑ‡∏≠‡πÇ‡∏ü‡∏ô‡πÄ‡∏ó‡πá‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö (iphoneX)            |\n",
      "|        |                 |                 | ‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡∏°‡∏≤‡∏Å‡∏Å ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏à‡∏∞‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡∏ã‡∏±‡∏°‡∏ã‡∏∏‡∏á        |\n",
      "|        |                 |                 | #iPhoneX #iPhoneTH https://t‚Ä¶                      |\n",
      "| 7236   | 192             | cowboy751       | RT @cowboy751: iPhone 8: no headphones             |\n",
      "|        |                 |                 | iPhone 10: no homebutton                           |\n",
      "|        |                 |                 | iPhone 12: no camera                               |\n",
      "|        |                 |                 | iPhone 14: no battery                              |\n",
      "|        |                 |                 | iPhone 16: no phone #AppleEve‚Ä¶                     |\n",
      "| 7202   | 997             | its_kachi       | RT @its_kachi: How you gotta sleep next to your    |\n",
      "|        |                 |                 | girl after you cop the new #iPhoneX                |\n",
      "|        |                 |                 | https://t.co/SVZKVsmm9u                            |\n",
      "| 7002   | 2931            | ElijahMiano     | RT @ElijahMiano: iPhone 8: no headphones           |\n",
      "|        |                 |                 | iPhone 10: no homebutton                           |\n",
      "|        |                 |                 | iPhone 12: no camera                               |\n",
      "|        |                 |                 | iPhone 14: no battery                              |\n",
      "|        |                 |                 | iPhone 16: no phone #AppleE‚Ä¶                       |\n",
      "| 6910   | 12600           | _Do_t           | RT @_Do_t: iPhoneX„ÅØ14‰∏á„Å†„Åë„Å©„Ç´„Ç§„Ç∂„ÇÆ„Ç¢„ÅØ„Åü„Å£„Åü5‰∏á„ÅßÈõªË©±Ê©üËÉΩ„Å´Âä†„Åà„Å¶ËñÑÊ±ö„ÅÑ„Ç™„É´ |\n",
      "|        |                 |                 | „Éï„Çß„Éé„ÇØ„ÇíÁÅ∞„Å´„Åô„Çã„Åì„Å®„ÅåÂá∫Êù•„Çã„Çì„Å†„ÄÄ„ÄÄ„ÄÄ„Å©„Å°„Çâ„ÇíË≤∑„ÅÜ„Åπ„Åç„ÅãÂêõ„Å´„ÇÇ„Çè„Åã„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„Åã„Å™„ÅÅ‚Ä¶Ôºü |\n",
      "| 6381   | 811405          | KTHopkins       | RT @KTHopkins: Hey, beautiful ladies. What do you  |\n",
      "|        |                 |                 | think of #iPhoneX #FaceID? https://t.co/lPfLyg4dcR |\n",
      "| 6149   | 94780           | SuperSaf        | RT @SuperSaf: Apple, \"Face ID can't be fooled      |\n",
      "|        |                 |                 | easily.\"                                           |\n",
      "|        |                 |                 |                                                    |\n",
      "|        |                 |                 | Arya Stark, \"We'll see about that\"                 |\n",
      "|        |                 |                 |                                                    |\n",
      "|        |                 |                 | #AppleEvent #iPhoneX https://t.co/tTIjVbcBkV       |\n",
      "+--------+-----------------+-----------------+----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "#Find most popular twitter at a exactly time, and find the most popular people, \n",
    "#locate the people who has the highest business value\n",
    "\n",
    "#find top 15 retweet, 5 top follower \n",
    "file = open('output','w')\n",
    "output = []\n",
    "for F in allFiles:\n",
    "    with open(F) as tweetfile:\n",
    "        statuses = json.load(tweetfile)\n",
    "\n",
    "    retweets = []\n",
    "    for status in statuses:\n",
    "        L = []\n",
    "        for i in retweets:\n",
    "            L.append(i[3])\n",
    "        if status['text'] in L:\n",
    "            continue\n",
    "        if 'retweeted_status' in status:\n",
    "            retweets.append(\n",
    "                 (status['retweet_count'], \n",
    "                  status['retweeted_status']['user']['followers_count'], \n",
    "                  status['retweeted_status']['user']['screen_name'],\n",
    "                  status['text']))      \n",
    "\n",
    "\n",
    "    # Slice off the first 5 from the sorted results and display each item in the tuple\n",
    "    ScrName = []\n",
    "    for row in sorted(retweets, reverse=True)[:15]:\n",
    "        ScrName.append((row[1],row[2],row[0]))\n",
    "\n",
    "    pt = PrettyTable(field_names=['Count','followers_count', 'Screen Name',  'Text'])\n",
    "    [pt.add_row(row) for row in sorted(retweets, reverse=True)[:15]]\n",
    "    pt.max_width['Text'] = 50\n",
    "    pt.align= 'l'\n",
    "    output = (F,sorted(ScrName,reverse = True)[0:5])\n",
    "    file.write('\\n'+str(output)+'\\t\\n')\n",
    "\n",
    "\n",
    "print(\"Data Saved: output\")\n",
    "\n",
    "#print(ScrName)\n",
    "#print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
    "\n",
    "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "    * What data you collected? \n",
    "    * Why this topic is interesting or important to you? (Motivations)\n",
    "    * How did you analyse the data?\n",
    "    * What did you find in the data? \n",
    " \n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through email to Prof. Paffenroth (rcpaffenroth@wpi.edu) *and* the TA Wen Liu (wliu3@wpi.edu).\n",
    "\n",
    "#### We auto-process the submissions so make sure your subject line is *exactly*:\n",
    "\n",
    "### DS501 Case Study 1 Team ??\n",
    "\n",
    "#### where ?? is your team number.\n",
    "        \n",
    "** Note: Each team just needs to submits one submission **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "** Totoal Points: 120 **\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Notebook:  **\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Qestion 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) Select a topic that you are interested in.\n",
    "    Points: 6 \n",
    "    \n",
    "    (2) Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million. Please check whether the total number of tweets collected is larger than 200?\n",
    "    Points: 10 \n",
    "    \n",
    "    \n",
    "    (3) Store the tweets you downloaded into a local file (txt file or json file)\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    1. Word Count\n",
    "\n",
    "    (1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Plot a table of the top 30 words with their counts \n",
    "    Points: 4 \n",
    "    \n",
    "    2. Find the most popular tweets in your collection of tweets\n",
    "    plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n",
    "    Points: 4 \n",
    "    \n",
    "    3. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "    (1) plot a table of the top 10 hashtags, \n",
    "    Points: 4 \n",
    "\n",
    "    (2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Get the list of all friends and all followers of the twitter user.\n",
    "    Points: 4 \n",
    "\n",
    "    (3) Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "\n",
    "    (4) Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "    \n",
    "    (5) Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table\n",
    "    Points: 4 \n",
    "  \n",
    "    -----------------------------------\n",
    "    Qestion 4:  Business question\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API.  Come up with a business question and describe how Twitter data can help you answer that question.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Report: communicate the results**\n",
    "    Points: 20\n",
    "\n",
    "(1) What data you collected?\n",
    "    Points: 5 \n",
    "\n",
    "(2) Why this topic is interesting or important to you? (Motivations)\n",
    "    Points: 5 \n",
    "\n",
    "(3) How did you analyse the data?\n",
    "    Points: 5 \n",
    "\n",
    "(4) What did you find in the data?\n",
    "(please include figures or tables in the report, but no source code)\n",
    "    Points: 5 \n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Slides (for 10 minutes of presentation): Story-telling **\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
